{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:07:39.092976Z",
     "start_time": "2019-04-12T03:07:39.088172Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle as pkl\n",
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adblock is necessary for selenium to run smoothly on the recipe pages\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_extension('/Applications/AdBlock.crx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "recipes = []\n",
    "num_pages = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:07:20.450201Z",
     "start_time": "2019-04-12T03:07:20.441636Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_urls(page):\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrapes all URLs of a search page on allrecipes.com\n",
    "    \n",
    "    Parameters:\n",
    "        page (str): a valid allrecipes.com search page url\n",
    "    Returns:\n",
    "        urls (list): a list of urls from the results of the search page\n",
    "    \"\"\"\n",
    "    \n",
    "    text = requests.get(page).text\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    \n",
    "    urls = []\n",
    "    for link in soup.find_all(class_='fixed-recipe-card__title-link')[::2]:\n",
    "        try:\n",
    "            urls.append(link['href'])\n",
    "        except KeyError:\n",
    "            print('No')\n",
    "    \n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T04:32:00.520651Z",
     "start_time": "2019-04-12T04:32:00.489917Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ingredients(url):    \n",
    "    \n",
    "    \"\"\"\n",
    "    Scrapes the ingredients of a recipe page in metric measurements on allrecipes.com. \n",
    "    This method uses both Selenium and BeautifulSoup since there are interactive elements \n",
    "    on the page which convert the measurements to metric. \n",
    "    \n",
    "    Parameters:\n",
    "        url (str): a valid allrecipes.com recipe page url\n",
    "    Returns:\n",
    "        ingredients (list): a list of ingredients for a single recipe on allrecipes.com\n",
    "    \"\"\"\n",
    "    \n",
    "    driver = webdriver.Chrome(executable_path='/Applications/chromedriver', options=options)\n",
    "    driver.get(url)\n",
    "    metric_1 = '//a[@class=\"servings-adust-trigger\"]'\n",
    "    metric_2 = '//li[@class=\"adjust-servings__select\"]'\n",
    "    metric_3 = '//a[@id=\"btn-adjust\"]'\n",
    "    driver.find_element_by_xpath(metric_1).click()\n",
    "    time.sleep(.1)\n",
    "    driver.find_elements_by_xpath(metric_2)[1].click()\n",
    "    time.sleep(.1)\n",
    "    driver.find_element_by_xpath(metric_3).click()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    driver.close()\n",
    "    \n",
    "    name = soup.find(class_='recipe-summary__h1').get_text()\n",
    "    ingredient_soup = soup.find_all('li', class_='checkList__line ng-scope')\n",
    "    ingredients = []\n",
    "    for line in ingredient_soup:\n",
    "        if line.findChild():\n",
    "            try:\n",
    "                ingredients.append(line.findChild().get_text().strip())\n",
    "            except AttributeError:\n",
    "                pass\n",
    "    \n",
    "    return ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T02:40:13.482095Z",
     "start_time": "2019-04-12T02:40:13.394224Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cookie_page(url):\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrapes all features of a recipe page on allrecipes.com\n",
    "    \n",
    "    Parameters:\n",
    "        url (str): a valid allrecipes.com recipe page url\n",
    "    Returns:\n",
    "        (dict): name (str): name of the recipe\n",
    "                rating (str): recipe rating\n",
    "                num_ratings (str): number of ratings\n",
    "                num_reviews (str): number of reviews\n",
    "                made_it (str): number of people who made the recipe\n",
    "                prep_time (str): preparation time\n",
    "                servings (str): number of servings\n",
    "                calories (str): number of calories\n",
    "                num_photos (str): number of photos for the recipe\n",
    "                oven_temp (str): oven temperature\n",
    "                ingredients (list): list of ingredients}\n",
    "                \n",
    "    \"\"\"\n",
    "    \n",
    "    text = requests.get(url).text\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    \n",
    "    name = soup.find(class_='recipe-summary__h1').get_text()\n",
    "    rating = soup.find(class_='rating-stars')['data-ratingstars']\n",
    "    num_photos = soup.find(class_='picture-count-link').get_text()\n",
    "    oven_temp = soup.find(text=re.compile('degrees'))\n",
    "    \n",
    "    try:\n",
    "        num_ratings = soup.find('h4', class_='helpful-header').get_text()\n",
    "    except:\n",
    "        num_ratings = np.nan\n",
    "        \n",
    "    try: \n",
    "        made_it = soup.find(class_='made-it-count').next_element.get_text()\n",
    "    except:\n",
    "        made_it = np.nan\n",
    "    \n",
    "    try:\n",
    "        prep_time = soup.find(class_='ready-in-time').get_text()\n",
    "    except:\n",
    "        prep_time = np.nan\n",
    "    \n",
    "    try:\n",
    "        servings = soup.find(id='metaRecipeServings')['content']\n",
    "    except:\n",
    "        servings = np.nan\n",
    "\n",
    "    try:    \n",
    "        calories = soup.find(class_=\"nutrition-trigger\").findChild()['aria-label']\n",
    "    except:\n",
    "        calories = np.nan\n",
    "    \n",
    "    try:\n",
    "        num_reviews = soup.find(class_='recipe-reviews__header--count').get_text()\n",
    "    except:\n",
    "        num_reviews = np.nan\n",
    "        \n",
    "    ingredients = get_ingredients(url)\n",
    "\n",
    "    print(f'{name} scraped')\n",
    "    return {'name': name,\n",
    "            'rating': rating,\n",
    "            'num_ratings': num_ratings,\n",
    "            'num_reviews': num_reviews,\n",
    "            'made_it': made_it,\n",
    "            'prep_time': prep_time,\n",
    "            'servings': servings,\n",
    "            'calories': calories,\n",
    "            'num_photos': num_photos,\n",
    "            'oven_temp': oven_temp,\n",
    "            'ingredients': ingredients}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:09:50.097651Z",
     "start_time": "2019-04-12T03:07:45.184387Z"
    }
   },
   "outputs": [],
   "source": [
    "# get recipe page urls for num_pages of search results\n",
    "for i in range(1,num_pages+1):\n",
    "    page = 'https://www.allrecipes.com/search/results/?wt=chocolate%20chip%20cookies&sort=re&page=' + str(i)\n",
    "    urls.extend(get_urls(page))\n",
    "    time.sleep(1+random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:11:58.742336Z",
     "start_time": "2019-04-12T03:11:58.738179Z"
    }
   },
   "outputs": [],
   "source": [
    "# only keep the recipes which are actually cookies\n",
    "cookie_urls = [url for url in urls if url.find('cookie') != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T20:06:18.080790Z",
     "start_time": "2019-04-11T19:54:11.837222Z"
    }
   },
   "outputs": [],
   "source": [
    "# scrape all pages\n",
    "for url in cookie_urls:\n",
    "    recipes.append(get_cookie_page(url))\n",
    "    time.sleep(1+random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T03:09:08.566948Z",
     "start_time": "2019-04-11T03:09:08.542615Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T17:57:20.505647Z",
     "start_time": "2019-04-11T17:57:20.450809Z"
    }
   },
   "outputs": [],
   "source": [
    "# SAVE FILE\n",
    "pd.to_pickle(df, 'test_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
